{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonjoy1s/ML/blob/main/Module_20_AdaBoost_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ef381e",
      "metadata": {
        "id": "47ef381e"
      },
      "source": [
        "\n",
        "# ðŸ“˜ Module 20: AdaBoost (Adaptive Boosting) â€“ Practice Notebook\n",
        "\n",
        "This is a **full practice notebook with detailed guidance and TODO blocks**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deae16a0",
      "metadata": {
        "id": "deae16a0"
      },
      "source": [
        "\n",
        "## 0. Notebook Setup\n",
        "\n",
        "We start by importing all required libraries.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c02353",
      "metadata": {
        "id": "83c02353"
      },
      "outputs": [],
      "source": [
        "# TODO: Import all required libraries (Done for you)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705290cd",
      "metadata": {
        "id": "705290cd"
      },
      "source": [
        "\n",
        "## 1. Understanding the Dataset\n",
        "\n",
        "You can begin with a **synthetic binary classification dataset**. or with any exisiting dataset.\n",
        "\n",
        "Focus questions:\n",
        "- Are the classes easily separable?\n",
        "- Will a weak learner struggle?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad549cd",
      "metadata": {
        "id": "6ad549cd"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate a binary classification dataset\n",
        "# Hint:\n",
        "# - n_samples around 500\n",
        "# - n_features = 2\n",
        "# - class_sep > 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "908d8093",
      "metadata": {
        "id": "908d8093"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualize the dataset using a scatter plot\n",
        "# Color points by class label\n",
        "\n",
        "# plt.scatter(...)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "zHvChlK854qQ"
      },
      "id": "zHvChlK854qQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "27816016",
      "metadata": {
        "id": "27816016"
      },
      "source": [
        "\n",
        "## 2. Trainâ€“Test Split\n",
        "\n",
        "Before any model training, we split the data.\n",
        "\n",
        "Why?\n",
        "- To evaluate generalization\n",
        "- To avoid lying to ourselves\n",
        "\n",
        "Standard split:\n",
        "- 70% training\n",
        "- 30% testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d1ce24",
      "metadata": {
        "id": "b7d1ce24"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the dataset into training and testing sets\n",
        "# Use test_size=0.3 and random_state=42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40c1320",
      "metadata": {
        "id": "c40c1320"
      },
      "source": [
        "\n",
        "## 3. Baseline Weak Learner (Decision Stump)\n",
        "\n",
        "Before AdaBoost, we test **one weak learner alone**.\n",
        "\n",
        "We intentionally restrict the model:\n",
        "- max_depth = 1\n",
        "- This is called a **decision stump**\n",
        "\n",
        "Expectation:\n",
        "- Accuracy will not be impressive\n",
        "- That is the point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0074ebf",
      "metadata": {
        "id": "c0074ebf"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a DecisionTreeClassifier with max_depth=1\n",
        "# SVM, Logistic Regression\n",
        "# This is our weak learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8430cb16",
      "metadata": {
        "id": "8430cb16"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the weak learner\n",
        "# TODO: Predict on test data\n",
        "# TODO: Calculate and print accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3ca4d3",
      "metadata": {
        "id": "7b3ca4d3"
      },
      "source": [
        "\n",
        "## 4. AdaBoost Classifier â€“ Core Practice\n",
        "\n",
        "Now we combine **many weak learners** using AdaBoost.\n",
        "\n",
        "Key idea:\n",
        "- Each learner focuses more on previous mistakes\n",
        "- Misclassified samples get more attention\n",
        "- Correctly classified samples slowly matter less\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84e5b80",
      "metadata": {
        "id": "f84e5b80"
      },
      "outputs": [],
      "source": [
        "# TODO: Initialize AdaBoostClassifier\n",
        "# Use:\n",
        "# - base_estimator = decision stump\n",
        "# - n_estimators = 50\n",
        "# - learning_rate = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e023ee",
      "metadata": {
        "id": "b1e023ee"
      },
      "outputs": [],
      "source": [
        "# TODO: Train AdaBoost on training data\n",
        "# TODO: Predict on test data\n",
        "# TODO: Evaluate accuracy\n",
        "# TODO: Print classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abaec55a",
      "metadata": {
        "id": "abaec55a"
      },
      "source": [
        "\n",
        "## 5. Weak Learner vs AdaBoost Comparison\n",
        "\n",
        "Now we compare:\n",
        "- One weak learner\n",
        "- Many weak learners working together\n",
        "\n",
        "Expectation:\n",
        "- AdaBoost should outperform a single stump\n",
        "- If not, something is wrong\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3964a4b",
      "metadata": {
        "id": "d3964a4b"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a comparison table\n",
        "# Columns:\n",
        "# - Model\n",
        "# - Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e047961f",
      "metadata": {
        "id": "e047961f"
      },
      "source": [
        "\n",
        "## 6. Effect of Number of Estimators\n",
        "\n",
        "AdaBoost performance depends heavily on:\n",
        "- Number of estimators\n",
        "\n",
        "More is not always better.\n",
        "\n",
        "Your job:\n",
        "- Experiment\n",
        "- Observe\n",
        "- Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbad0dee",
      "metadata": {
        "id": "fbad0dee"
      },
      "outputs": [],
      "source": [
        "# TODO: Try different n_estimators values\n",
        "# Example: [5, 10, 20, 50, 100]\n",
        "\n",
        "# Store accuracy for each value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ceb4b0",
      "metadata": {
        "id": "b0ceb4b0"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot n_estimators vs accuracy\n",
        "# Label axes clearly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a107c7",
      "metadata": {
        "id": "00a107c7"
      },
      "source": [
        "\n",
        "## 7. Effect of Learning Rate\n",
        "\n",
        "Learning rate controls **how aggressively** AdaBoost updates sample weights.\n",
        "\n",
        "Intuition:\n",
        "- High learning rate â†’ fast but risky\n",
        "- Low learning rate â†’ slow but stable\n",
        "\n",
        "You will verify this experimentally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960cd22e",
      "metadata": {
        "id": "960cd22e"
      },
      "outputs": [],
      "source": [
        "# TODO: Experiment with different learning_rate values\n",
        "# Example: [0.01, 0.1, 0.5, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f5372c",
      "metadata": {
        "id": "c3f5372c"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot learning_rate vs accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "868cc05f",
      "metadata": {
        "id": "868cc05f"
      },
      "source": [
        "\n",
        "## 8. Feature Importance in AdaBoost\n",
        "\n",
        "AdaBoost can tell us:\n",
        "- Which features were more influential\n",
        "\n",
        "This depends on:\n",
        "- How often a feature is used in splits\n",
        "- How strong the corresponding learners were\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7a9a0c",
      "metadata": {
        "id": "7b7a9a0c"
      },
      "outputs": [],
      "source": [
        "# TODO: Extract feature importance from AdaBoost\n",
        "# TODO: Plot feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7210227f",
      "metadata": {
        "id": "7210227f"
      },
      "source": [
        "\n",
        "## 9. Reflection (Mandatory)\n",
        "\n",
        "Answer in your own words.\n",
        "\n",
        "1. Why is AdaBoost called *adaptive*?\n",
        "2. What happens to misclassified samples after each iteration?\n",
        "3. Why do we prefer weak learners instead of strong ones?\n",
        "4. When should AdaBoost not be used?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6488b54b",
      "metadata": {
        "id": "6488b54b"
      },
      "source": [
        "\n",
        "## 10. Bonus Challenge (Optional)\n",
        "\n",
        "Replace the decision stump with **Logistic Regression** as the base estimator.\n",
        "\n",
        "Questions:\n",
        "- Does AdaBoost still work?\n",
        "- Should you do this in practice?\n",
        "- Why or why not?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ffd936",
      "metadata": {
        "id": "e3ffd936"
      },
      "outputs": [],
      "source": [
        "# TODO: Replace DecisionTreeClassifier with LogisticRegression or SVM\n",
        "# Train AdaBoost again\n",
        "# Compare performance"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}